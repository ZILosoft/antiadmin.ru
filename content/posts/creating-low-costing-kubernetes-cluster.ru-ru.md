---
title: "Поднимаем себе не дорогой кубер кластер"
date: 2023-09-02T19:04:01-03:00
Summary: "В поисках кубер кластера, для бомжей"
draft: false
---
## Вместо 1000 слов
Эта статья, как и итоговый кластер не были бы возможны, без [TimeWeb](https://timeweb.cloud/r/cz01395), спасибо им, что они существуют и развиваются. Если честно, я думал, что они уже давно мертвы.

## Предисловие
### Почему TimeWeb?
С первого взгляда, можно подумать, что я это заказная статья.
Со второго взгляда, можно подумать, что я жадная крыса, которая хочет заработать на [рефералке](https://timeweb.cloud/r/cz01395).
И вообще, можно подумать, что я интегрирую это в контент, по причине `{{ .SomeReason }}`

На самом деле, все куда проще. TimeWeb тупо оказался первым встреченным адекватным вариантом.

### Никита, ну что опять за хуйня?
Одним ни разу не добрым и не солнечным Аргентинским утром, я в очередной раз проснулся от того, что какая-то сраная местная птица дерет свое горло так, как-будто ее режут. 
Звучит это по хлеще, чем целый хор деревенских петухов.
К сожалению, местное законодательство не позволяет мне иметь дома ружье, так, что я просто жду, когда эта птица сдохнет от старости или ее сожрет кто-то покрупнее, например [Каракара](https://ru.wikipedia.org/wiki/%D0%9E%D0%B1%D1%8B%D0%BA%D0%BD%D0%BE%D0%B2%D0%B5%D0%BD%D0%BD%D0%B0%D1%8F_%D0%BA%D0%B0%D1%80%D0%B0%D0%BA%D0%B0%D1%80%D0%B0), живущий на соседнем дереве.

Возможно это эта шакальная птица в зуме x6 орет у меня по утрам.

![bird-1.jpg](/images/creating-low-costing-kubernetes-cluster/bird-1.jpg)

Казалось бы, при чем тут вообще какая-то сраная птица. Да хуй ее знает.

Короче, мне нужно поднять себе кубер, без лишних вопросов.

### А в чем собственно проблематика?
Я, как и многие вынужденные иммигранты, которые катапультировались из того пиздеца, по причине той хуйни, имею российский паспорт и не имею никаких карточек, кроме Российских.
Стало быть, оплачивать зарубежные сервисы мне не очень удобно.

Хотя по началу у меня были отличные (а главное рабочие!) криптокарты, но криптоцыгане синхронно, а главное не зависимо друг от друга все проебали.

### Требования
Собственно, пораскинув мозгами и максимально отфильтровав последствия проф деформации каждодневного созерцания графиков высоко нагруженных продуктов, я пришел к следующим выводам: 

* Бюджет - не больше 2к рублей в месяц, при том это верхняя граница, желательно бы поменьше.
* В целях экономии - я подниму 1 мастер ноду и все в нее запихаю. И да, мне похуй, что так не надо делать
* 4гб должно быть достаточно для всех(с)
* Минимум 2 ядра от 2.8ггц
* На диск в моем контексте можно забить, вообще. SSD, NvME, иопсы, хуепсы - это все конечно лишним не будет, но переплачивать я за это конечно же не стану.
* Виртуализация должна быть обязательно, я уже давно привык просто поднять контейнер и забыть, а не настраивать ебучее окружение.
* Должна быть возможность как вертикального, так и горизонтального масштабирования
* Должна быть приватная сеть, с которой я не буду ебаться сам

Короче, естественно мы рассматриваем только облака

### Ресерчим
Итак, с одной стороны - есть российский паспорт, российские карточки, желание не башлять за это больше, чем ведро острых крыльев в KFC. 
С другой стороны есть иностранные провайдеры, которые горят желанием запихать тебе твой паспорт в твое же очко, да поглубже. 

И вообще - нахуй им твои кровавые деньги не нужны.

Стало быть начинаем поиск с российских провайдеров.

#### Яндекс.Облако
Что ж, начнем с компании, которая знает толк в облаках, высоких нагрузках, а также в миграции своих облачных решений в опенсорс. 
Конечно же я говорю о Яндексе и сервисе [Яндекс.Облако](https://cloud.yandex.ru/).

С определенного времени я являюсь постоянным пользователем фри тира яндекс облака, по скольку храню там некоторые свои проекты. 
Поэтому уже и аккаунт есть и доверие (и даже деньги на счету!), что на самом деле играет не последнюю роль.

Ну с, давайте посмотрим, что они могут предложить.
Конфигурируем 20гб обычного HDD, 2 самых дешевых ядра, 4гб оперативки, и конечно же 1 внешний IP.

![yandex-cloud-005cpu.png](/images/creating-low-costing-kubernetes-cluster/yandex-cloud-005cpu.png)

Получаем 1.35к рублей в месяц. Вообще не то, что хотелось бы видеть, при том, что гарантированная доля CPU всего 5%.
По ощущениям, на этом кубер даже не запустится. А если и запустится, вряд ли этим можно будет пользоваться.
Проверять я это конечно не буду. 
Если говорить про 100% CPU, то получается 3к рублей в месяц - в бюджет не попадает.

Чисто теоретически, можно сделать машину прерываемой, написать скрипт, которые будет ее поднимать и посадить его на крону, но чет хуй знает, оставим это на крайний случай.

#### Selectel
Продолжим наши бич изыскания, в поисках решений, где же все-таки найти сервера под высокие нагрузки, по цене 4 бутылок пива. 

В фокус внимания попадает [компания, которая из каждого чайника орет про соответствие 152-ФЗ](https://selectel.ru/).
Сразу скажу, что меня люто тригерит упоминание любого Российского закона вне зависимости от его адекватности.
Не то, чтобы я был против чего-то подобного, но в данный момент, несмотря на всю мою любовь к России, я не хочу иметь с ней ничего общего в том виде, в котором она сейчас существует и управляется.

Выбираем похожую конфигурацию и проц из шаред пула.

![selectel-01cpu.png](/images/creating-low-costing-kubernetes-cluster/selectel-01cpu.png)

В целом выходит +- так же, по скольку нет возможности взять в аренду 0.05 ядра.
Особого смысла в этом не вижу, а красующаяся надпись 152-ФЗ все еще заставляет мое очко разрываться.
Прости [Selectel](https://selectel.ru/), не быть мне твоим клиентом в ближайшее время. 


#### Другие варианты
Естественно, в первую очередь я предпринимал попытки аренды на [OVH](https://ovh.cloud) с разовой годовой оплатой или на [DO](https://digitalocean.com). 
Но к сожалению, сложность поиска способа это великолепие оплатить свела на нет все мое желание чем-либо заниматься.

За то, в этот момент я столкнулся с парадоксом сознания. Оказывается, платить 38$ в месяц за тачку это не дорого, а платить 2000 в рублях - дохуя. Вот такие дела.

### Конец изысканий
И вот, да. 
Казалось бы - выходной слит на бесполезную хуйню(я бы поспорил, какая хуйня бесполезнее - эта или та, которой я буду заниматься дальше), настроение испорчено, а птица доживает еще пару лет своей жизни, продолжая насмехаться надо мной по утрам.
Но тут, меня дергает мысль о том, что раньше я пользовался услугами шаред хостингов, в целом - не торт, но если брать VPS и поебаться - будет работать.

Что ж, время доставать из памяти, чем я пользовался, когда был PHP обезьяной. 

На ум пришли только 3 сервиса: 
* [Timeweb](https://timeweb.cloud/r/cz01395)
* [Beget](https://beget.com/ru)
* [Reg.ru](https://reg.ru/)

#### Reg.ru
[Reg.ru](https://reg.ru/) я сразу отмел из-за личной неприязни. Если так подумать, меня даже название тригерит, но я хуй знает, почему. Даже не знаю, заслуженно или нет - ну просто так получилось. 

#### Beget
[Beget](https://beget.com/ru) в целом оказался на вид норм вариантом, вроде есть приватные сетки, очень сносный прайс за 2 ядра/2 гига, только игровую видеокарту не завезли.

![beget-2cpu.png](/images/creating-low-costing-kubernetes-cluster/beget-2cpu.png)

В общем надо брать. Угадайте, к чему я приебался?
Нет, не к уебищному дизайну.

![beget-register.png](/images/creating-low-costing-kubernetes-cluster/beget-register.png)

Да простят меня ребята из [Beget](https://beget.com/ru), но я не хочу регистрироваться там, где мне в лицо тычут битрикс хостингом прямо при регистрации.
Ебать, как же у меня полыхало. Больше всего на свете я ненавижу 3 вещи: холодное пиво, битрикс и быдло. 

#### TimeWeb
И вот, остается только [TimeWeb](https://timeweb.cloud/r/cz01395)
Что ж, посмотрим, что мы имеем.

А имеем мы п̶р̶и̶в̶я̶з̶а̶н̶н̶ы̶е̶ ̶а̶к̶к̶а̶у̶н̶т̶ы̶ ̶в̶с̶е̶х̶ ̶м̶о̶и̶х̶ ̶с̶т̶а̶р̶ы̶х̶ ̶к̶л̶и̶е̶н̶т̶о̶в̶:

* Относительно адекватный функционал и интерфейс. Обычно бывает так, что ты ничего не ждал, но все равно разочарован. Тут же все наоборот.

![timeweb-interface.png](/images/creating-low-costing-kubernetes-cluster/timeweb-interface.png)

* Выбор региона, с возможностью `!поменять страну!`

![timeweb-interface.png](/images/creating-low-costing-kubernetes-cluster/timeweb-region-select.png)

* Сочный прайс с поминутным списанием, все, как в наших любимых облаках. Разве что за просмотр баланса счет не выставляют.

![timeweb-price.png](/images/creating-low-costing-kubernetes-cluster/timeweb-price.png)

Что ж, в целом, все выглядит очень оптимистично.

## Закупаемся
По скольку ноды выходят дешевле, чем я ожидал, мы можем себе позволить сразу 2 ноды, а не одну.

**Оглашаю итоговый конфиг:**
Мастер нода - Premium NVMe 355р/мес, 1x3.3 ГГц, 2Гб, 30Гб NVMe
Воркер нода - Premium NVMe 1100р/мес, 4x3.3 ГГц, 8Гб, 80Гб NVMe

**Мастер ноду изначально берем `2 ядерную`**, иначе мы просто не сможем запустить на ней кубер.
Как только мы закончим первоначальную настройку кластера - мы можем снизить количество ядер до 1.

Все ноды на CentOS 8!

### СТОП, ЧТО?
Какой еще нахуй сентос? У тебя что, есть желание поебаться с SELinux?

Ну, 2 года сидел на Fedora, теперь меня такой хуйней в расплох не застать!

А вообще, в процессе подготовки кластера, я использовал убунту ноды, однако, сколько бы я не ебался - у меня ни разу не вышло без танцев с бубном завести сеть в кубере.
В процессе очередной переустановки системы на ноде, я случайно ткнулся в сентос и не сразу это заметил. 


После 30й минуты дебага отсутствия apt на машине, я обнаружил, что в общем-то я и не на убунте. 

И о чудо, какого-то хуя, все заработало! При чем с первого раза, я даже не поверил. Как так? Да хуй его знает.

А SELinux я нахуй выключил, такие дела.

## Накатываем кубер
Дальнейшая инструкция рассчитана на людей, которые понимают, что они делают.

Если вы не понимаете, что вы делаете - я вас уверяю, вам это не нужно.

### Подготовка
**Нам понадобится:**
* Вера во всех богов кубера
* Lens IDE. OpenLens или нет - вам решать, мне лично как [в припеве](https://open.spotify.com/track/0oBltdPwAyPkzKYaNhXE1t?si=bae617f9d29a4838). Хотите CLI - ебитесь с ним сами.
* SSH ключ
* Деньги на серваки.
Вы можете купить 1 ноду пожирнее и снять с нее теинт, не вижу в этом проблем, мы ведь не прод поднимаем, хотя хуй знает мотивы того человека, что решил использовать этот гайд. 
Однако нужно учесть, что вряд ли получится снизить потребление оперативы мастер нодой ниже, чем 1100МБ, отсюда 2гб - жизненно необходимый минимум.

### Поднимаем серваки
Настало время действовать, покупаем серваки на CentOS 8, предварительно добавив свой SSH ключ и **ПРЕДВАРИТЕЛЬНО выбрав приватную сеть из списка уже созданных**.

Цепляемся к нашей мастер ноде по SSH и погнали. 

- Сразу же выключаем swap, вырубаем нахуй SELinux и ребутаемся
```bash
sudo sed -i '/swap/d' /etc/fstab
sudo swapoff -a
sudo setenforce 0
sudo sed -i --follow-symlinks 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux
reboot
```

- После перезагрузки, мы можем приступить к настройке мастер ноды.
```bash
export NODE_NAME=
export EXTERNAL_NODE_IP=
export INTERNAL_NODE_IP=
```
Имя потрудитесь придумать сами, Внешние и внутренние IP можно взять в панели TimeWeb.

Дальнейший код будет описан так, чтобы его можно было просто копипастить в терминал полной конструкцией.

Все для удобства. 

- Для начала задаем нашей машине имя, чтобы потом было проще ориентироваться в кластере
```bash
sudo hostnamectl set-hostname $NODE_NAME
```

- Добавляем наш домен с именем машины в `/etc/hosts`
```bash
echo "$INTERNAL_NODE_IP $NODE_NAME" | sudo tee -a /etc/hosts
```

- Далее, устанавливаем containerd
```bash
sudo yum check-update
sudo yum install -y yum-utils device-mapper-persistent-data lvm2
sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
sudo yum install -y docker-ce
```

- Какого-то хуя, по умолчанию выключена очень важная для нас говнина - CRI runtime API, поэтому, при попытке сделать `kubeadm init` - вы разъебетесь.

Что ж, исправим эту хуету заранее
```bash
mkdir -p /etc/containerd && containerd config default > /etc/containerd/config.toml
systemctl restart containerd
```

- Добавляем репозиторий кубера и выкачиваем всего лишь 5̶ ̶б̶и̶н̶а̶р̶е̶й̶ 3 бинаря
```bash
cat <<EOF > /etc/yum.repos.d/kubernetes.repo 
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg 
EOF
sudo yum install -y kubelet kubeadm kubectl
```

- Включаем и запускаем докер и кублет
```bash
sudo systemctl enable kubelet
sudo systemctl start kubelet
sudo systemctl enable docker
sudo systemctl start docker
sudo systemctl start docker
```

- Обновляем правила фаервола и включаем мосты в iptables
```bash
sudo firewall-cmd --permanent --add-port=179/tcp
sudo firewall-cmd --permanent --add-port=5473/tcp
sudo firewall-cmd --permanent --add-port=4789/udp
sudo firewall-cmd --permanent --add-port=6443/tcp
sudo firewall-cmd --permanent --add-port=2379-2380/tcp
sudo firewall-cmd --permanent --add-port=10250/tcp
sudo firewall-cmd --permanent --add-port=10251/tcp
sudo firewall-cmd --permanent --add-port=10252/tcp
sudo firewall-cmd --permanent --add-port=10255/tcp
sudo firewall-cmd --reload

cat <<EOF > /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
sudo sysctl --system
```

- И наконец инициализируем мастер ноду
```bash
sudo kubeadm init --control-plane-endpoint=$EXTERNAL_NODE_IP
```
Прошу заметить, что я нарочно не указал CIDR подсети, чтобы все встало из коробки.

- Полируем это все сверху установкой кубеконфига, по скольку мы все выполняли из под рута.
```bash
export KUBECONFIG=/etc/kubernetes/admin.conf
```
Не забудь сохранить этот конфиг, он нам еще пригодится для подключения.

Хотя вы конечно же можете добавить его в стандартную директорию, чтобы не потерять
```bash
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

- Осталось только накатить сетевой плагин.
Собственно ради простоты последнего шага мы и не указывали CIDR подсети при инициализации мастер ноды.
```bash
kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.25.0/manifests/calico.yaml
```

- Последним штрихом на мастер ноде будет забрать конфиг джоина воркера
```bash
kubeadm token create --print-join-command
```

Ну, вроде с мастер нодой разъебались без приключений. Если бы мы открыли бутылку пива в начала покупки мастер ноды, мы бы не успели выпить даже половину. 
Я бы сказал, что это ахуенный результат!

### Добавляем воркер ноду
- Выполняем абсолютно те же самые действия, что и с мастер нодой до момента с фаерволом.
В данном случае нам просто не нужно столько портов.
```bash
sudo firewall-cmd --permanent --add-port=179/tcp
sudo firewall-cmd --permanent --add-port=5473/tcp
sudo firewall-cmd --permanent --add-port=4789/udp
sudo firewall-cmd --permanent --add-port=10251/tcp
sudo firewall-cmd --permanent --add-port=10255/tcp
sudo firewall-cmd --reload

cat <<EOF > /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
sudo sysctl --system
```

- Присоединаем воркер ноду, предварительно заменив айпишник на ВНУТРЕННИЙ IP мастер ноды
```bash
kubeadm join {{ .Ip }}:6443 --token {{ .Token }} \
--discovery-token-ca-cert-hash sha256:{{ .Sha256 }}
```

На данный момент мы уже закончили все необходимые настройки, поэтому можем смело уменьшать количество ядер на мастер ноде до 1.

## Добавляем жизненно важные штуки
Для следующих шагов понадобится Lens IDE, потому, что так проще.
Так что скачиваем его и подключаемся к нашему кластеру при помощи конфига, который мы сохранили ранее.


### Добавляем кластер в Lens IDE
Думаю, что ничего сложного в этом шаге не будет. Не забудьте, что если не добавить на кластер иконку, в виде кота - боги кубера этого не одобрят и кластер не будет работать.

Лично я выбрал вот этого очаровашку:

![kuber-cat-icon.jpeg](/images/creating-low-costing-kubernetes-cluster/kuber-cat-icon.jpeg)


Фотки котов можно выбрать на [https://thiscatdoesnotexist.com](https://thiscatdoesnotexist.com). 
Ах да...

Меняем план, прежде, чем продолжить, нужно остановиться, поднять stylegan и сгенерировать подходящую пикчу. Или просто взять худшего качества [отсюда](https://thesecatsdonotexist.com/)

### Мониторинг
Открываем наш кластер и создаем новый неймспейс `monitoring`. 
Добавляем в ваш хельм прометеус репу
```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
```

И устанавливаем прометеус стек
Осторожно, следующая команда может пахать 15-20 минут. 

Лично я запускал ее с флагом `--debug`, чтобы убедиться, что что-то вообще делается
```bash
helm install kube-prometheus-stack prometheus-community/kube-prometheus-stack --namespace=monitoring
```

После установки, мы можем затуннелить графану и посмотреть на наш кластер.
Доступы можно посмотреть в секрете `kube-prometheus-stack-grafana` в неймспейсе `monitoring`

![grafana-graphics.png](/images/creating-low-costing-kubernetes-cluster/grafana-graphics.png)

### Ингресс
Тут в целом ничего не отличается от предыдущего этапа. 

Также создаем неймспейс `ingress` и накатываем в него ингресс контроллер. 
В моем случае это был nginx-ingress из репозитория [kubernetes/ingress-nginx](https://kubernetes.github.io/ingress-nginx)


## Послесловие
Я уложился в 1.5к рублей в месяц, при этом заимел 4 свободных ядра по 3.3 и 8гб оперативы.
Считаю, что для кубера это даже очень неплохая сделка.

**Что мы имеем в итоге:**

* готовый к использованию кубер кластер, заливай ворклоады и принимай трафик
* 4 свободных ядра по 3.3ггц
* 8гб оперативы
* отдельную мастер ноду
* мониторинг и возможность алертинга
* возможность масштабироваться до усрачки

Однако. А собственно, на кой хуй было так ебаться?

У меня закончилась лицензия 1Password, которую я по очевидным причинам не продлю и я решил не мелочиться. 

А при чем тут вообще кубер?

Ну, надеюсь, когда-нибудь позже я расскажу, как поднять в нем битварден.

А вот еще одна шакальная птица в зуме x6
![bird-2.jpg](/images/creating-low-costing-kubernetes-cluster/bird-2.jpg)